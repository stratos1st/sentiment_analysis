{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stratos/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded KNeighborsClassifier_CountVectorizer_1500.pickle\n",
      "classifier= KNeighborsClassifier\tvectorizer= CountVectorizer\tscore=  0.32539820928914326\n",
      "loaded LogisticRegression_CountVectorizer_1500.pickle\n",
      "classifier= LogisticRegression\tvectorizer= CountVectorizer\tscore=  0.32107406523026466\n",
      "loaded RandomForestClassifier_CountVectorizer_1500.pickle\n",
      "classifier= RandomForestClassifier\tvectorizer= CountVectorizer\tscore=  0.3247492972804286\n",
      "loaded SVC_CountVectorizer_1500.pickle\n",
      "classifier= SVC\tvectorizer= CountVectorizer\tscore=  0.32330871341998485\n",
      "loaded XGBClassifier_CountVectorizer_1500.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stratos/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier= XGBClassifier\tvectorizer= CountVectorizer\tscore=  0.30414008879148874\n",
      "loaded KNeighborsClassifier_TfidfVectorizer_1500.pickle\n",
      "classifier= KNeighborsClassifier\tvectorizer= TfidfVectorizer\tscore=  0.32552781265075464\n",
      "loaded LogisticRegression_TfidfVectorizer_1500.pickle\n",
      "classifier= LogisticRegression\tvectorizer= TfidfVectorizer\tscore=  0.32005712869819064\n",
      "loaded RandomForestClassifier_TfidfVectorizer_1500.pickle\n",
      "classifier= RandomForestClassifier\tvectorizer= TfidfVectorizer\tscore=  0.3246682752457179\n",
      "loaded SVC_TfidfVectorizer_1500.pickle\n",
      "classifier= SVC\tvectorizer= TfidfVectorizer\tscore=  0.3212417411032377\n",
      "loaded XGBClassifier_TfidfVectorizer_1500.pickle\n",
      "classifier= XGBClassifier\tvectorizer= TfidfVectorizer\tscore=  0.3025013254009077\n",
      "all classifiers score=  0.3192574253091575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stratos/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy    \n",
    "\n",
    "# read correct ansers\n",
    "Location = r'/home/stratos/Desktop/ted_Project/twitter_data/SemEval2017_task4_subtaskA_test_english_gold.txt'\n",
    "df = pd.read_csv(Location, error_bad_lines=False,\n",
    "                    names=['no1','cent'],sep='\\t')\n",
    "# df=df[:-1]\n",
    "# ytrain=df.drop(columns=['no1','no2','tweet'])\n",
    "\n",
    "# read test_data\n",
    "infile = open(\"lemmatized_tweets_test.pickle\",'rb')\n",
    "test_data = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "# # concatinate tokens. ending up with a filtered tweet\n",
    "tok=[]\n",
    "for tweet in test_data:\n",
    "    tmp=''\n",
    "    for word in tweet:\n",
    "        tmp=tmp+' '+word\n",
    "    tok.append(tmp)\n",
    "test_data=tok\n",
    "\n",
    "\n",
    "sz=12000\n",
    "attributes=1500\n",
    "\n",
    "\n",
    "test_vectori=[\n",
    "    [CountVectorizer(max_features=attributes)],\n",
    "    [TfidfVectorizer(max_features=attributes)]\n",
    "]\n",
    "\n",
    "test=[\n",
    "    [neighbors.KNeighborsClassifier(n_jobs=4,algorithm='brute',weights='distance')],\n",
    "    [LogisticRegression(n_jobs=4)],\n",
    "    [RandomForestClassifier(n_jobs=4,n_estimators=250)],\n",
    "    [svm.SVC(kernel='linear', C=1, probability=True)],\n",
    "    [XGBClassifier()]\n",
    "]\n",
    "\n",
    "\n",
    "test1=[x+test_vectori[0] for x in test]\n",
    "test2=[x+test_vectori[1] for x in test]\n",
    "\n",
    "test=test1+test2   \n",
    "\n",
    "\n",
    "prediction=[]\n",
    "for classifier, vectori in test:\n",
    "    _vectorizer = vectori\n",
    "    _xtrain = _vectorizer.fit_transform(test_data)\n",
    "    \n",
    "    file_name=classifier.__class__.__qualname__ +\"_\"+vectori.__class__.__qualname__+\"_\"+str(attributes)+\".pickle\"\n",
    "    # read w2v\n",
    "    infile = open(file_name,'rb')\n",
    "    classifi = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "    print(\"loaded \"+file_name)\n",
    "    \n",
    "    tmp=classifi.predict(_xtrain[:sz])\n",
    "    prediction.append(tmp) #predict on the validation set\n",
    "    print(\"classifier= \"+classifier.__class__.__qualname__ +\"\\tvectorizer= \"+vectori.__class__.__qualname__+\"\\tscore= \",end=\" \")\n",
    "    print(f1_score(df['cent'][:sz], tmp,average='macro'))#evaluate on the validation set\n",
    "    \n",
    "\n",
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count) \n",
    "    \n",
    "#voting prosses\n",
    "ans=[]\n",
    "for i in range (sz):\n",
    "    list2 = [item[i] for item in prediction]\n",
    "    ans.append(most_frequent(list2))\n",
    "ans=numpy.asarray(ans)\n",
    "\n",
    "print(\"all classifiers score= \",end=\" \")\n",
    "print(f1_score(df['cent'][:sz], ans,average='macro'))#evaluate on the validation set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
